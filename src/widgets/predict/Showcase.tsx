export const Showcase = () => {
  return <>
    <h2>Showcaseï¼šPredict fusions with TCGA exon counts.</h2>
    <h3>Overview</h3>
    <div>
      The accuracy and precision of predicting fusions at common cases.
    </div>
    <div>
      How to generate the training dataset?
      We take the annotation for fusions and generate a "positive sample" for each pair of fusion genes.
      Then we randomly choose genes which has already been used in "positive samples" to form pairs.
      Those random pairs are ensured not to be in fusion pairs,thus are "negative samples".
      In detail,for each sample of gene pair,we calculate the correlation matrix, partial correlation matrix and pearson
      p-value matrix.
      With those three matrixs as "X" and the fusion lable 1 or 0 as "Y", we generate a data_loader.
      At last,we split the data_loader into 80% train_loader for training and 20% test_loader for testing.
    </div>
    <div>
      As for the training process,we feed the matrixs into three different LSTM network,synthesize the output of the
      last
      LSTM cells of
      three LSTM networks using a sequential layer including dropout layer, linear layer and Sigmoid activation layer.
      The model's final output is a float number between [0,1],with which we can easily get the MSELoss between it and
      label 0/1.
      After that,we back propagate loss to optimize the model.
    </div>
    <div>
      Using fusion annotations from FusionGDB ( https://ccsm.uth.edu/FusionGDB/ ),
      We trained a model and its performance on Test set is:
    </div>
    <pre>{`
    "
    Accuracy on Test Set: 68.6777 %
    total: 3199 real=1,predict=1: 655 real=1,predict=0: 879 real=0,predict=1: 123 real=0,predict=0: 1542
    Precision on Test Set: 84.1902 %
    "
    Similarly,we trained a model using fusion annotations from ChimerSeq (https://www.kobic.re.kr/chimerdb_mirror/) and have results as:
    "
    Accuracy on Test Set: 66.0667 %
    total: 3000 real=1,predict=1: 948 real=1,predict=0: 559 real=0,predict=1: 459 real=0,predict=0: 1034
    Precision on Test Set: 67.3774 %
    "
    `}</pre>
    <div>As you can see,the results are not worthless as many sequence based methods are worse.</div>

    <h3>Less false positive when increasing threshold</h3>
    <div>Increase the threshold of being recognized as fusion and there is a significant precision increase.</div>
    <div>
      As illustrated before,the model's final output is a float number between [0,1].
      In previous tests, we assume there is fusion when the output is above 0.5 and get precision around 65%.
      To get lower false positive rate, we can increase the threshold of selecting fusions to 0.6/0.7/0.8/0.9.
    </div>
    <pre>{`
In the joint dataset .
Accuracy on Test Set: 63.6296 %
total: 9417 real=1,predict=1: 1863 real=1,predict=0: 2367 real=0,predict=1: 1058 real=0,predict=0: 4129
Precision on Test Set: 63.7795 %
Precision when above 0.6: 65.1246 % total num (positive and false positive) is 843
Precision when above 0.7: 74.1021 % total num is 529
Precision when above 0.8: 76.4463 % total num is 242
Precision when above 0.9: 83.8710 % total num is 31
  `}</pre>
    <div>We can see that,there is a clearly precision increase at higher threshold.</div>

    <h3>Robustness with different database</h3>
    <div>Use model trained from one database to predict fusions of another database to see whether the model will work
      for
      different databases.
    </div>
    <div>
      Fusion annotations from different database may be generated by various methods and can differ a lot.
      We test if the model trained with annotations from one database can be used to predict fusions from annother
      database.
      Using fusion annotations from FusionGDB ( https://ccsm.uth.edu/FusionGDB/ ),
      We trained a model named "model0" and its performance on Test set is:
    </div>
    <pre>{`
  "
Accuracy on Test Set: 68.6777 %
total: 3199 real=1,predict=1: 655 real=1,predict=0: 879 real=0,predict=1: 123 real=0,predict=0: 1542
Precision on Test Set: 84.1902 %
"
Similarly,we trained a model named "model1" using fusion annotations from ChimerSeq (https://www.kobic.re.kr/chimerdb_mirror/) and have results as:
"
Accuracy on Test Set: 66.0667 %
total: 3000 real=1,predict=1: 948 real=1,predict=0: 559 real=0,predict=1: 459 real=0,predict=0: 1034
Precision on Test Set: 67.3774 %
"

Then,we use model0 to predict the dataset generated with ChimerSeq (model1's training set).
Results
"
Accuracy on Test Set: 52.7000 %
total: 3000 real=1,predict=1: 196 real=1,predict=0: 1311 real=0,predict=1: 108 real=0,predict=0: 1385
Precision on Test Set: 64.4737 %
"

While the results of predicting the dataset generated with FusionGDB (model2's training set) using model1 is:
"
Accuracy on Test Set: 62.3007 %
total: 3199 real=1,predict=1: 958 real=1,predict=0: 576 real=0,predict=1: 630 real=0,predict=0: 1035
Precision on Test Set: 60.3275 %
"
  `}</pre>
    <div>
      We can clearly see that, the model is still "predictive" for predicting fusions from different dataset.
      And the "characteristic" of model remains.
    </div>
    <div>
      For example "model0" have a strict standard for being predicted as fusion ( the truth label of fusion and not
      fusion
      is 1:1 while (948+459):(559+1034) is lower. )
    </div>
    <div>
      So,when predicting another dataset whose signs of fusion are more ambiguous, it misses more positive genes.(
      Accuracy:52.7000 % with predicted_1 : predicted_0 =(196+108):(1311+1385) )But as the standard is stricter,the
      precision is pretty high( 64.4737 % ), which is very important.( false negative
      is much more acceptable than false positive in this case.)
    </div>

    <h3>Robustness with less samples for each exon</h3>
    <div>
      For a model trained with 1218 samples for each exon,we reduce the samples to 50,100,200,500 to test if there is
      significant performance drop.
    </div>
    <div>
      Using ChimerSeq fusion annotations ( https://www.kobic.re.kr/chimerdb_mirror/), <br/>
      we train the model with 1218 samples for each exon and predict fusions within two genes with only 50,100,200,500
      samples. <br/>
      The results are as follows:
    </div>
    <pre>{`
predict with all(1218) samples, accuracy:66.0667% precision: 67.3774%
predict with 500 samples, accuracy: 64.7900% precision: 65.2067%
predict with 200 samples, accuracy: 64.8750% precision: 65.1616%
predict with 100 samples, accuracy: 63.2100% precision: 62.8252%
predict with 50 samples, accuracy: 62.0650% precision: 60.6647%
  `}</pre>
    <div>
      And there is annother thing worth mentioning, considering p value into learning model is important for
      robustness. <br/>
      Here is the results using model whose only difference with our final model is not taking p value into
      consideration:
    </div>
    <pre>{`
predict with all(1218) samples, accuracy:65.4250% precision: 68.4211%
predict with 500 samples, accuracy: :66.5700% precision: 67.5902%
predict with 200 samples, accuracy: 64.9400% precision: 63.7115%
predict with 100 samples, accuracy: 62.9550% precision: 60.3448%
predict with 50 samples, accuracy: 60.5450% precision: 57.2951%
  `}</pre>
    <div>We can see that after considering p value, there is smaller accuracy and precision drop when using less
      samples.
    </div>
  </>
}